{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OOP 22 - Hören 2 - wav2vec groß",
      "provenance": [],
      "authorship_tag": "ABX9TyPIov3/wMiuvMTjtkbleZxU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olafthiele/oop22/blob/main/OOP_22_H%C3%B6ren_2_wav2vec_gro%C3%9F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hören 2 - Großes wav2vec Modell\n",
        "\n",
        "Dieses Notebook erkennt mit einem großen Modell von 1GB Größe eine heruntergeladene Testdatei.\n",
        "\n",
        "Grundsätzlicher Algorithmus von Facebook/Meta: https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/\n",
        "\n",
        "Leicht einzusetzende Modelle mit Code von Hugging Face: https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads\n",
        "\n",
        "Mit Laufzeittyp GPU starten, die Zeitunterschiede zu sehen.\n",
        "\n",
        "---\n",
        "\n",
        "Allgemein:\n",
        "\n",
        "Dieses Notebook läuft auf den Servern von Google, es verändert nichts auf Ihrem lokalen Rechner. Alle Eingaben werden Beendigung gelöscht.\n",
        "\n",
        "Colab Notebooks enthalten Text- oder Codeblöcke. Codeblöcke werden durch SHIFT-ENTER ausgeführt (oder Play-Symbol oben links klicken).\n",
        "\n",
        "Solange ein Block ausgeführt wird, wird nicht mehr die Nr [3] des Blocks, sondern ein Kreis angezeigt.\n",
        "\n",
        "Sie können beliebig Daten verändern, das geschieht nur für Sie."
      ],
      "metadata": {
        "id": "tsgq2_aCpbxY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iNeJxesTAzw"
      },
      "outputs": [],
      "source": [
        "# Grundsätzliche Libs installieren für Audios und Oberfläche\n",
        "!pip install torchaudio ipywebrtc\n",
        "!sudo apt update\n",
        "!sudo apt install ffmpeg\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "\n",
        "# Audio nutzen\n",
        "from ipywebrtc import AudioRecorder, CameraStream\n",
        "import torchaudio\n",
        "\n",
        "# Recording ermöglichen\n",
        "from IPython.display import Audio\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "# Testdateien laden\n",
        "!wget http://ainblick.de/test/oop1.wav\n",
        "!wget http://ainblick.de/test/oop2.wav"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Lib installieren von: https://github.com/jonatasgrosman/asrecognition\n",
        "!pip install asrecognition"
      ],
      "metadata": {
        "id": "hmhrkgPWVx9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from asrecognition import ASREngine\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "# Modell von Hugging Face herunterladen\n",
        "asr = ASREngine(\"de\", model_path=\"jonatasgrosman/wav2vec2-large-xlsr-53-german\")\n",
        "end = time.time()\n",
        "print(\"Dauer: \", end - start)\n",
        "\n",
        "audio_paths = [\"oop2.wav\"]\n",
        "start = time.time()\n",
        "transcriptions = asr.transcribe(audio_paths)\n",
        "end = time.time()\n",
        "print(\"Dauer: \", end - start)\n",
        "\n",
        "transcriptions"
      ],
      "metadata": {
        "id": "5z71AI0BWt2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selbst aufnehmen\n",
        "camera = CameraStream(constraints={'audio': True,'video':False})\n",
        "recorder = AudioRecorder(stream=camera)\n",
        "recorder"
      ],
      "metadata": {
        "id": "618djjVgqXTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('recording.webm', 'wb') as f:\n",
        "    f.write(recorder.audio.value)\n",
        "!ffmpeg -i recording.webm -acodec pcm_s16le -ar 16000 recorded.wav -loglevel panic -y\n",
        "sig, sr = torchaudio.load(\"recorded.wav\")\n",
        "print(sig.shape)\n",
        "Audio(data=sig, rate=sr)"
      ],
      "metadata": {
        "id": "Xslfj_vsqX1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_paths = [\"recorded.wav\"]\n",
        "transcriptions = asr.transcribe(audio_paths)\n",
        "\n",
        "transcriptions"
      ],
      "metadata": {
        "id": "idsb5l6Aqd6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "G3zki5K8cSFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "\n",
        "\n",
        "model_id = \"jonatasgrosman/wav2vec2-large-xlsr-53-german\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_id).to(\"cuda\") # .to() für GPU\n"
      ],
      "metadata": {
        "id": "3gDazuAIczu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "audio, rate = torchaudio.load(\"recorded.wav\")\n",
        "input_values = processor(audio, return_tensors = \"pt\", sampling_rate=rate).input_values\n",
        "logits = None\n",
        "with torch.no_grad():\n",
        "    logits = model(input_values[0].to(\"cuda\")).logits # für GPU\n",
        "    # logits = model(input_values[0]).logits # für CPU\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "transcription = processor.batch_decode(predicted_ids)\n",
        "end = time.time()\n",
        "print(\"Dauer: \", end - start)\n",
        "print(\"Ergebnis: \" + transcription[0])"
      ],
      "metadata": {
        "id": "I8Tr3QcEf9pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_ids[0])\n",
        "print()\n",
        "i = 1\n",
        "for s in sorted(processor.tokenizer.get_vocab()):\n",
        "  print(str(i) + \" -> \" + str(s))\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "uR_8F_SDeXdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XAtQfWnpx7pt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}